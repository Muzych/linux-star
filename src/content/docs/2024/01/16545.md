---
author: 硬核老王
category: 硬核观察
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 1446
date: '2024-01-09 17:31:45'
editorchoice: false
excerpt: "? OpenAI 称不用版权材料训练不出来 ChatGPT\r\n? 美国去年仅净增长 700 个 IT 工作岗位\r\n? 确保 AI 安全的理论仍未就绪\r\n»
  \r\n»"
fromurl: ''
id: 16545
islctt: false
largepic: /data/attachment/album/202401/09/172958occey1b4zog1szy1.jpg
permalink: /article-16545-1.html
pic: /data/attachment/album/202401/09/172958occey1b4zog1szy1.jpg.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: "? OpenAI 称不用版权材料训练不出来 ChatGPT\r\n? 美国去年仅净增长 700 个 IT 工作岗位\r\n? 确保 AI 安全的理论仍未就绪\r\n»
  \r\n»"
tags:
- AI
- 工作
thumb: false
title: '硬核观察 #1241 OpenAI 称不用版权材料训练不出来 ChatGPT'
titlepic: true
translator: ''
updated: '2024-01-09 17:31:45'
---

![](/data/attachment/album/202401/09/172958occey1b4zog1szy1.jpg)


![](/data/attachment/album/202401/09/173011jlzzwnnvof5g2f28.png)


### #1 OpenAI 称不用版权材料训练不出来 ChatGPT


OpenAI 在给英国上议院的文件中表示，如果不能访问受版权保护的内容，就无法建立像 ChatGPT 这样的人工智能系统。该公司表示，人工智能工具必须包含受版权保护的作品，以 “充分代表人类智慧和经验的多样性和广度”。OpenAI 认为，使用来自互联网的数据训练人工智能模型属于合理使用规则的范畴，该规则允许重新使用受版权保护的作品。另外，OpenAI 也宣布，网站可以从 2023 年 8 月开始阻止 OpenAI 的网络爬虫访问其数据。


*（插图：DA/f7aafbbf-3d3e-4864-8ed0-56b86fd3d634）*



> 
> **[消息来源：The Verge](https://www.theverge.com/2024/1/8/24030283/openai-nyt-lawsuit-fair-use-ai-copyright)**
> 
> 
> 



> 
> 老王点评：虽然是否属于版权法的合理使用还需要法律上的讨论，但我倾向于给予 AI 一个野蛮生长的机会。
> 
> 
> 


![](/data/attachment/album/202401/09/173110g2job69t329kr0tq.png)


### #2 美国去年仅净增长 700 个 IT 工作岗位


根据美国劳工统计局的数据分析，尽管美国 2023 年第四季度创造了超过 21,000 个 IT 工作岗位，但去年净增长的 IT 工作岗位仅为 700 个，而前一年则为 26.7 万个。目前，由于技能不匹配，有近 10 万个未填补的工作岗位和 10.1 万多名失业的 IT 专业人员。另外，尽管对拥有人工智能、安全、开发和区块链技能的人的需求仍然很旺盛，但入门级 IT 需求正在萎缩，入门级职位正在被人工智能取代。


*（插图：DA/f5dee957-f727-414a-bfb9-18efdda5c06b）*



> 
> **[消息来源：The Register](https://www.theregister.com/2024/01/08/700_it_jobs_us/)**
> 
> 
> 



> 
> 老王点评：上有经济不景气，下有 AI 追杀，IT 人真难。
> 
> 
> 


![](/data/attachment/album/202401/09/173128wnlo4ulpzi404a0x.png)


### #3 确保 AI 安全的理论仍未就绪


美国国家标准与技术研究院（NIST）的计算机科学家 <ruby> 阿波斯托尔·瓦西列夫 <rt>  Apostol Vassilev </rt></ruby> 表示，预测性和生成性人工智能系统仍然容易受到各种攻击。他说：“尽管人工智能和机器学习取得了重大进展，但这些技术很容易受到攻击。……确保人工智能算法安全的理论问题尚未解决。”他最近与其他人共同撰写的一篇论文试图对人工智能系统带来的安全风险进行分类，重点关注了四个具体的安全问题：规避攻击、中毒攻击、隐私攻击和滥用攻击。总的来说，结果并不乐观。论文最后指出，可信的人工智能目前需要在安全性与公平性和准确性之间做出权衡。


*（插图：DA/3ea75ca9-198a-414c-8fc0-57b543c031d8）*



> 
> **[消息来源：The Register](https://www.theregister.com/2024/01/05/nist_ai_security/)**
> 
> 
> 



> 
> 老王点评：AI 的安全也存在一个不可能三角吗？
> 
> 
>