---
author: 硬核老王
category: 硬核观察
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 1572
date: '2023-08-29 17:52:00'
editorchoice: false
excerpt: "? WordPress 公司提供百年域名注册选项\r\n? IBM 开发出新型模拟 AI 芯片，大幅降低能耗\r\n? Meta 发布了编程的大语言模型\r\n»
  \r\n»"
fromurl: ''
id: 16139
islctt: false
largepic: /data/attachment/album/202308/29/175020p6vuzox134uf6ove.jpg
permalink: /article-16139-1.html
pic: /data/attachment/album/202308/29/175020p6vuzox134uf6ove.jpg.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: "? WordPress 公司提供百年域名注册选项\r\n? IBM 开发出新型模拟 AI 芯片，大幅降低能耗\r\n? Meta 发布了编程的大语言模型\r\n»
  \r\n»"
tags:
- 域名
- 编程
- AI
thumb: false
title: '硬核观察 #1108 WordPress 公司提供百年域名注册选项'
titlepic: true
translator: ''
updated: '2023-08-29 17:52:00'
---

![](/data/attachment/album/202308/29/175020p6vuzox134uf6ove.jpg)


![](/data/attachment/album/202308/29/175130b4z5y5cubyobwjl4.jpg)


### WordPress 公司提供百年域名注册选项


WordPress 公司称，希望保存故事、照片、声音和视频等数字资产的家庭，或希望保护和记录公司历史的创始人可以使用该产品。该服务的费用为 3.8 万美元，也就是平均每年 380 美元。此方案还包括跨越多个地理区域的内容备份，带宽不受限制，以及 24/7 小时的技术支持。



> 
> **[消息来源：Silicon Republic](https://www.siliconrepublic.com/business/wordpress-domain-registration-100-years)**
> 
> 
> 



> 
> 老王点评：这钱真白交，我不觉得 100 年后还会有现在的互联网。
> 
> 
> 


![](/data/attachment/album/202308/29/175114dlyb4ze3hivaopln.jpg)


### IBM 开发出新型模拟 AI 芯片，大幅降低能耗


IBM 的研究团队近期发布了一款新型的模拟 AI 芯片设计，这种基于大脑模式的芯片设计，可以模拟人脑神经网络的工作方式，实现复杂的计算任务，同时保持高效的能源使用。其性能已经达到了 GPU 的级别，却只有同等级 GPU 1/14 的能耗。这种芯片芯片使用相变存储器（PCM），PCM 不是记录数字系统中的 0 或 1，而是非晶态和晶态之间的连续值，它可将神经网络的权重直接编码到物理芯片上。IBM 的原型芯片能编码 3500 万个 PCM 装置，单个芯片最多能支持 1700 万参数的模型。



> 
> **[消息来源：IBM](https://research.ibm.com/blog/analog-ai-chip-low-power)**
> 
> 
> 



> 
> 老王点评：模拟 AI 芯片以其更低的能耗和类似人脑的处理方式，未来有望在 AI 应用中扮演更重要的角色。
> 
> 
> 


![](/data/attachment/album/202308/29/175149l30xrvlvqbc74xm4.jpg)


### Meta 发布了编程的大语言模型


Meta 发布了 Code Llama，这是一种基于 Llama 2 的新型大型语言模型，旨在通过生成和调试代码来帮助程序员。它与 ChatGPT 和 GitHub Copilot 类似，你可以用对话要求它编写代码。Code Llama 可以用 Python、Java、C++、PHP、TypeScript、C#、Bash 脚本等多种编程语言进行编程。该模型有三个规模：7B、13B 和 43B，其中 7B 和 13B 模型速度更快，更适合需要低延迟的任务，如实时代码完成，并且可以在单个消费级 GPU 上运行。



> 
> **[消息来源：Ars Technica](https://arstechnica.com/information-technology/2023/08/meta-introduces-code-llama-an-ai-tool-aimed-at-faster-coding-and-debugging/)**
> 
> 
> 



> 
> 老王点评：这样说，可以在程序员自己的笔记本上跑了？另外，我才知道 Llama 这个缩写原来也是一个英文单词，意思是美洲羊驼，你知道这种动物的。
> 
> 
>