---
author: Sourav Rudra
category: 新闻
comments_data:
- date: '2023-03-31 17:27:12'
  message: 肯定没有openAI的ChatGPT好用
  postip: 39.144.248.162
  username: 来自39.144.248.162的 Mobile Safari 16.4|iOS 16.4 用户
count:
  commentnum: 1
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 4487
date: '2023-03-31 09:54:18'
editorchoice: false
excerpt: 你需要一款 ChatGPT 的平替？还得是开源的？看起来我们已经被卷入了与 ChatGPT 的开源大战。
fromurl: https://news.itsfoss.com/open-source-model-dolly/
id: 15678
islctt: true
largepic: /data/attachment/album/202303/31/095413k2xax88kyki1jqg8.jpg
permalink: /article-15678-1.html
pic: /data/attachment/album/202303/31/095413k2xax88kyki1jqg8.jpg.thumb.jpg
related: []
reviewer: wxy
selector: lkxed
summary: 你需要一款 ChatGPT 的平替？还得是开源的？看起来我们已经被卷入了与 ChatGPT 的开源大战。
tags:
- ChatGPT
- AI
thumb: false
title: 号称可以成为 ChatGPT 平替的开源模型 “Dolly”
titlepic: true
translator: lxbwolf
updated: '2023-03-31 09:54:18'
---


> 
> 你需要一款 ChatGPT 的平替？还得是开源的？看起来我们已经被卷入了与 ChatGPT 的开源大战。
> 
> 
> 


![open source model dolly](/data/attachment/album/202303/31/095413k2xax88kyki1jqg8.jpg)


Databricks 这家软件公司，在各个领域都有所建树，尤其是在数据仓库和基于人工智能的解决方案方面。


最近，随着 ChatGPT 横空出世，Meta、谷歌甚至 Mozilla 都开始效仿 ChatGPT。


而现在，Databricks 开源了其 <ruby> <a href="https://en.wikipedia.org/wiki/Large_language_model?ref=its-foss-news">  大型语言模型 </a> <rt>  large language model </rt></ruby>（LLM）“Dolly”，也正在以自己的方式进行尝试。


我们一起来看看它。


**发生了什么？** 在最近的公告中，Databricks 介绍了他们号称 “**廉价构建**” 的 LLM，使用 [EleutherAI](https://www.eleuther.ai/?ref=its-foss-news) 的已经开源的参数 [模型](https://huggingface.co/EleutherAI/gpt-j-6B?ref=its-foss-news) 提供功能。


他们在该模型基础上稍作调整，赋予了 Dolly 指令诸如头脑风暴和文本生成的能力。


当你拿它与 GPT-3 中的 **1750 亿个参数** 比较时，Dolly 的 **60 亿个参数** 就可能显得微不足道。


但是，当 Databricks 的人看到即使数据量与 GPT-3 相差这么多，Dolly 也能 **展示很多与 ChatGPT 相同的能力** 时，他们感到非常震惊。


下面是他们展示的其中一个例子：


![a screenshot of how dolly performs in an open question and answer scenario](/data/attachment/album/202303/31/095418ryvn7bib74vi79r9.jpg)


原始模型使用了 [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?ref=its-foss-news) 的数据，该模型由斯坦福大学以 Meta 的 [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/?ref=its-foss-news) LLM 为基础建立。


但是，正如你所看到的，原始模型产生了一个非常杂乱无章的结果，而 Dolly，通过不同的模型和调整，能够产生一个更为可用的答案。



> 
> ? 有趣的事实：“<ruby> 多莉 <rt>  Dolly </rt></ruby>” 名字取自世界上第一只克隆羊。
> 
> 
> 


**为什么是现在？** 根据 Databricks 的说法，他们认为 \*\*许多公司更愿意建立自己的模型，\*\*而不是将数据发送给某个紧紧掌握模型只对外提供 API 的集中式供应商。


许多公司可能不愿意将他们最敏感的数据交给第三方，然后在模型质量、成本和所需行为方面进行各种权衡。


**你想看看吗？**


当然，但有一个问题。


你必须 **使用他们的平台来使用 Dolly**，他们已经开源了一个 [Databricks 笔记本](https://github.com/databrickslabs/dolly?ref=its-foss-news)，可以帮助你在 Databricks 上构建它。


此外，如果你想获得训练好的权重，你必须联系他们。不过我不确定他们是否会免费提供使用权。


总而言之，这种开源其模型的举动应该对其他公司有好处，可以保护他们的数据、节省运营成本，其他公司也能使用它创建自己的模型。


你可以查看其 [公告博客](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html?ref=its-foss-news)，以了解更多技术细节和其他计划。




---


via: <https://news.itsfoss.com/open-source-model-dolly/>


作者：[Sourav Rudra](https://news.itsfoss.com/author/sourav/) 选题：[lkxed](https://github.com/lkxed/) 译者：[lxbwolf](https://github.com/lxbwolf) 校对：[wxy](https://github.com/wxy)


本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出